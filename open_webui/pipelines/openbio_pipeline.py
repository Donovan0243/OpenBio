import os
import sys
from typing import List, Dict, Union, Generator, Iterator, Any
from langchain_core.messages import HumanMessage, AIMessage, ToolMessage, BaseMessage

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ° Python è·¯å¾„
ROOT_DIR = os.path.abspath(os.path.join(os.path.dirname(__file__), "../../"))
sys.path.append(ROOT_DIR)

from src.core.settings import configure_settings
from src.core.rag import initialize_rag_system

class Pipeline:
    def __init__(self):
        self.name = "OpenBio RAG Pipeline"
        print("[OpenBio] åˆå§‹åŒ– Pipeline...")
        self.workflow = None
        try:
            self.original_dir = os.getcwd()
            os.chdir(ROOT_DIR)
            print(f"[DEBUG] åˆ‡æ¢åˆ°æ ¹ç›®å½•: {ROOT_DIR} è¿›è¡Œåˆå§‹åŒ–")
            configure_settings()
            self.workflow = initialize_rag_system()
            print("[OpenBio] Pipeline åˆå§‹åŒ–æˆåŠŸ")
        except Exception as e:
            print(f"[OpenBio] åˆå§‹åŒ–é”™è¯¯: {str(e)}")
            raise
        finally:
            # åˆå§‹åŒ–åå³æ¢å¤åŸå§‹ç›®å½•ï¼Œé™¤éæœ‰å…¶ä»–éœ€è¦åœ¨ ROOT_DIR æ‰§è¡Œçš„æ“ä½œ
            if hasattr(self, 'original_dir'):
                 os.chdir(self.original_dir)
                 print(f"[DEBUG] åˆå§‹åŒ–åæ¢å¤ç›®å½•åˆ°: {self.original_dir}")


    async def on_startup(self):
        print("[OpenBio] Pipeline å¯åŠ¨")
        if self.workflow is None:
            print("[OpenBio] è­¦å‘Š: Workflow æœªåœ¨ __init__ ä¸­æˆåŠŸåˆå§‹åŒ–!")
            # æ­¤å¤„å¯èƒ½éœ€è¦æ›´å¥å£®çš„é”™è¯¯å¤„ç†æˆ–çŠ¶æ€æ£€æŸ¥

    async def on_shutdown(self):
        print("[OpenBio] Pipeline å…³é—­")


    def pipe(
        self, user_message: str, model_id: str, messages: List[Dict], body: dict
    ) -> Union[str, Generator, Iterator]:
        
        original_cwd = os.getcwd()
        if ROOT_DIR != original_cwd:
            os.chdir(ROOT_DIR)
            # print(f"[DEBUG] pipe: åˆ‡æ¢åˆ°æ ¹ç›®å½•: {ROOT_DIR} æ‰§è¡Œ workflow")

        if self.workflow is None:
            def error_gen():
                if ROOT_DIR != original_cwd: os.chdir(original_cwd)
                yield "[OpenBio] é”™è¯¯: RAG å·¥ä½œæµæœªåˆå§‹åŒ–ã€‚"
            return error_gen()

        try:
            inputs: Dict[str, Any] = {
                "messages": [
                    HumanMessage(content=user_message, additional_kwargs={"type": "user_question"})
                ]
            }

            def stream_workflow_responses():
                final_answer_content = None
                thinking_steps_started = False
                
                # type_labels ç°åœ¨ä¸»è¦ç”¨äºç»™æ¥è‡ª metadata.thinking_content çš„æ–‡æœ¬é…ä¸€ä¸ª emoji/å‰ç¼€
                type_labels = {
                    "routing_info": "ğŸ§­ Routing", 
                    "evaluation_info": "âš–ï¸ Evaluation",
                    "agent_step_info": "ğŸ¾ Agent Step", # ç”¨äº eutils_agent, blast_agent ç­‰çš„ thinking_content
                    "error_info": "â— Error Info",
                    "general_thought": "ğŸ¤” Thinking", # é€šç”¨æˆ–æœªçŸ¥èŠ‚ç‚¹çš„ thinking_content
                }
                
                print("[STREAM_DEBUG] Starting stream_workflow_responses generator (ONLY metadata.thinking_content for <think> block)...")

                for chunk_idx, chunk in enumerate(self.workflow.stream(inputs, {"recursion_limit": 25})):
                    print(f"\n[STREAM_DEBUG] Chunk {chunk_idx + 1}: {chunk}")
                    
                    for node_name, node_output_value in chunk.items():
                        print(f"[STREAM_DEBUG]   Processing Node: '{node_name}'")
                        if node_name == "__end__":
                            print("[STREAM_DEBUG]     Node is __end__, skipping.")
                            continue

                        # 1. æ£€æŸ¥ 'metadata' ä¸­æ˜¯å¦æœ‰ 'thinking_content' æ¥ç”Ÿæˆæ€è€ƒæ­¥éª¤
                        if isinstance(node_output_value, dict) and "metadata" in node_output_value:
                            metadata_dict = node_output_value.get("metadata")
                            if isinstance(metadata_dict, dict) and "thinking_content" in metadata_dict:
                                custom_think_text = metadata_dict.get("thinking_content")
                                if custom_think_text and isinstance(custom_think_text, str) and custom_think_text.strip():
                                    print(f"[STREAM_DEBUG]     Found 'thinking_content' in metadata from '{node_name}': {custom_think_text}")
                                    
                                    if not thinking_steps_started:
                                        print("[STREAM_DEBUG]       Starting <think> block.")
                                        yield "<think>\n"
                                        thinking_steps_started = True
                                    
                                    label_key = "general_thought" # é»˜è®¤æ ‡ç­¾
                                    if node_name == "router": label_key = "routing_info"
                                    elif node_name == "evaluator": label_key = "evaluation_info"
                                    elif "agent" in node_name.lower(): label_key = "agent_step_info"
                                    # æ£€æŸ¥é¡¶å±‚æ˜¯å¦æœ‰ status: errorï¼Œæ¥å†³å®šæ˜¯å¦ç”¨ error_info æ ‡ç­¾
                                    if isinstance(node_output_value, dict) and node_output_value.get("status") == "error":
                                        label_key = "error_info"
                                    
                                    label_prefix = type_labels.get(label_key, type_labels["general_thought"]) # è·å–æ ‡ç­¾å‰ç¼€
                                    line_to_yield = f"{label_prefix}: {custom_think_text.strip()}\n"
                                    print(f"[STREAM_DEBUG]         Yielding from thinking_content: {line_to_yield.strip()}")
                                    yield line_to_yield
                            else:
                                print(f"[STREAM_DEBUG]     'metadata' dict found for '{node_name}', but no 'thinking_content' key or it's empty.")
                        else:
                            print(f"[STREAM_DEBUG]     No 'metadata' key in output of node '{node_name}', or output is not a dict. Cannot check for thinking_content.")

                        # 2. å¤„ç† 'messages' åˆ—è¡¨ï¼Œä½†ä»…ä¸ºäº†æå– 'final_answer'
                        # å…¶ä»–ç±»å‹çš„æ¶ˆæ¯å°†ä¸å†ç”¨äºç”Ÿæˆ <think> å—çš„å†…å®¹
                        if isinstance(node_output_value, dict) and "messages" in node_output_value:
                            messages_in_node_output = node_output_value.get("messages", [])
                            if isinstance(messages_in_node_output, list):
                                print(f"[STREAM_DEBUG]     Checking {len(messages_in_node_output)} message(s) in '{node_name}' for final_answer.")
                                for msg_obj in messages_in_node_output:
                                    if isinstance(msg_obj, AIMessage) and hasattr(msg_obj, 'additional_kwargs') and msg_obj.additional_kwargs:
                                        msg_type = msg_obj.additional_kwargs.get("type")
                                        if msg_type == "final_answer":
                                            final_answer_content = str(msg_obj.content).strip()
                                            print(f"[STREAM_DEBUG]         Found final_answer in messages: {final_answer_content[:70]}...")
                                            # ä¸å†ä»æ­¤å¾ªç¯ yield é final_answer çš„å†…å®¹åˆ° <think> å—
                        elif isinstance(node_output_value, AIMessage): # å¤„ç†èŠ‚ç‚¹ç›´æ¥è¿”å›å•ä¸ª AIMessage çš„æƒ…å†µ
                            msg_obj = node_output_value
                            if hasattr(msg_obj, 'additional_kwargs') and msg_obj.additional_kwargs:
                                msg_type = msg_obj.additional_kwargs.get("type")
                                if msg_type == "final_answer":
                                    final_answer_content = str(msg_obj.content).strip()
                                    print(f"[STREAM_DEBUG]         Found final_answer directly from node '{node_name}': {final_answer_content[:70]}...")


                if thinking_steps_started:
                    print("[STREAM_DEBUG] Ending <think> block.")
                    yield "</think>\n"
                
                if final_answer_content:
                    print(f"[STREAM_DEBUG] Yielding final answer: {final_answer_content[:50]}...")
                    yield f"Answer: {final_answer_content}"
                else:
                    print("[STREAM_DEBUG] No final_answer_content found after all chunks.")
                    yield "[OpenBio] è­¦å‘Š: æ‰§è¡Œå®Œæˆï¼Œä½†æœªæ‰¾åˆ°æ˜ç¡®çš„ 'final_answer'ã€‚"
                
                if ROOT_DIR != original_cwd:
                    os.chdir(original_cwd)
                print("[STREAM_DEBUG] stream_workflow_responses generator finished.")

            return stream_workflow_responses()

        except Exception as e:
            import traceback
            error_str = str(e)
            print(f"[OpenBio Pipeline] æ‰§è¡Œè¿‡ç¨‹ä¸­æ•è·åˆ°å¼‚å¸¸: {error_str}")
            print(traceback.format_exc())
            if ROOT_DIR != original_cwd: os.chdir(original_cwd)
            def error_gen_exception():
                yield f"[OpenBio] ç³»ç»Ÿå†…éƒ¨é”™è¯¯ (æµå¼å¤„ç†): {error_str}"
            return error_gen_exception()